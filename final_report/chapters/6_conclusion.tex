\chapter{Conclusion and future work}
\label{ch:conclusion-and-future-work}
The aim of this project was to expand previous research to fix perceived flaws in the optimisation problem for
Mobile Edge Computing resource allocation. This was achieved by introducing the notion of time into the optimisation
model. As a result, a new optimisation problem presented in Section~\ref{sec:resource-allocation-optimisation-problem}
along with an auction mechanism proposed to deal with self-interested users (Section~\ref{sec:auctioning-of-tasks}). \\
To efficiently bid on auction tasks and allocation resources for a server's allocated tasks, Reinforcement Learning
agents were proposed that aimed to learn these policies. An implementation of an MEC environment was developed and
numerous Reinforcement Learning algorithms were implemented to train both auction and resource weighting agent. \\
The evaluation and testing of the implementation in Chapter~\ref{ch:testing-and-evaluation} found that agents could
efficiently learn the policy achieving significantly better than Fixed Resource Allocation mechanisms.
However it was found that $\sim$ 5\% of all tasks were not completed within their time frame. \\
This project has been viewed as a success but this author believes that more research and analysis of agents is
required before such systems can be implemented into real-life environments.

For future work into this project, this author believes that several additions to the proposed agents could greatly
improve their performance like n-step rewards~\citep{multi-step-dqn} and distributional
agents~\citep{distributional_dqn} that would improve Q value estimation within stochastic environment. An additional
heuristic for the policy gradient, would be to use a centralised critic~\citep{maddpg} that has been proposed in mix
competitive-cooperative environment to help multiple agents work together.

The word count of the Project can be found in \hyperref[app:project-management]{Appendix E}.
