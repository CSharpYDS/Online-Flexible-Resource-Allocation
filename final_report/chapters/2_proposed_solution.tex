\chapter{Proposed solution to problem}\label{ch:proposed-solution-to-problem}
In chapter~\ref{ch:project-problem}, the problem that this project address was outlined along with the reasoning for the
project. This chapter builds upon that giving a mathematical description of the problem (\ref{sec:optimisation-problem}).
Then separates the program into two sub-problems: task auctioning (addressed in sections~\ref{sec:task-auctioning})
and server to task resource allocation (addressed in section~\ref{sec:resource-allocation-solution}) that are each
discussed with novel solutions proposed. The last section of the chapter discusses a problem related to the problem
formulation as it reflects to reinforcement learning markov decision processes
(section~\ref{sec:markov-decision-process-description}).

\section{Optimisation problem}\label{sec:optimisation-problem}
% Todo add motiviation for why optimisation problem maybe
%Resource allocation traditionally been an area of applied mathematics originally design to running multiple
%programs in parallel by actually allocating small slices of time inwhich the task would run before switching to a new
%task. Because of the origins of the research, the program is normally described using formal mathematics. Therefore
%this section proposed a mathematical model to describe the proposed flexible resource allocation mechanisms.

Using the flexible resource allocation principle presented in~\cite{FlexibleResourceAllocation}, a format mathematical
description of the problem can be presented.

%In cloud
%computing, user would request a fix amount of resources, e.g. 2 cpu cores, 8GB ram, 10GB hard drive, etc, that is then
%set aside for the user who will pay by the minute for the allocation of the resources. However this standard cloud
%computing allocation model works effectively where the available resources to distribute are virtually unlimited and so
%the cloud provider does not consider to who and how resources are being distributed. Because of this, edge cloud
%computing which has significantly fewer resources must take the questions of resource allocation much more seriously.

%Therefore in previous work by~\cite{FlexibleResourceAllocation} proposed a principle of task flexibility allow for
%more flexible allocation mechanism in low resource capable environment with the aim of maximising the usage of
%available resources.
The principle is that for certain resources, the time taken for a operation to occur,
e.g.\ loading of a program, computing the program and sending of results, etc, is proportional to the amount of
resources allocated to completed the operation.
\footnote{This principle is not always true, for example, video decompression is a generally a single
thread operation and cannot be effectively multi-threaded. However for this project we only consider tasks
that can be parallelised effectively.}
Therefore instead of allowing the user to requesting a fixed amount of resources for loading, computing and sending back
the results of a program, the user would instead inform the server the total amount of bandwidth required,
computational power, etc for the task to be completed. Then the server can dynamically allocate its available resources
to all of its allocated tasks.
This is believed to be effective compared to standard resource allocation mechanism is that bottleneck can occur on
certain resource preventing additional tasks from being allocated due not the server not having the requested resources
available for the task.
Therefore using this principle, a modified version of a standard resource allocation formulation can be described
to maximise social welfare.

A sketch of the system is shown in Fig.~\ref{fig:system_model}.
We assume that in the system there is a set of $I = \{1,2,\ldots,\left|I\right|\}$ servers are heterogeneous in all
characters. Each server has a fixed availability of resources: storage for the code/data needed to run a task
(e.g., measured in GB), computation capacity in terms of CPU cycles per time interval (e.g., measured in FLOP/s),
and communication bandwidth to receive the data and to send back the results of the task after execution (e.g., measured in Mbit/s).
We denote these resources for server $i$: the storage capacity as $S_i$, computation capacity as $W_i$,
and the communication capacity as $R_i$.

\begin{figure}
    \centering
    \includegraphics{figures/system_model.pdf}
    \caption{System model}
    \label{fig:system_model}
\end{figure}

There is a set $J = \{1,2,\ldots,\left| J \right|\}$ of  different tasks that require service from one of the servers
in set $I = \{1,2,\ldots, \left| I \right|\}$. To run any of these tasks on a server requires storing the appropriate
code/data on the same server. These could be, for example, a set of images, videos or CNN layers in identification
tasks. The storage size of task $j$ is denoted as $s_j$ with the rate at which the program is transferred to the server
$i$ at time $t$ being $s^{'}_{i,j,t}$. For a task to be computed successfully, it must fetch and execute instructions
on a CPU. We consider the total number of CPU cycles required for the program to be $w_j$, where the rate at which the
CPU cycles are assigned to the task on server $i$ at time $t$ is $w^{'}_{i,j,t}$. Finally, after the task is run and
the results obtained, the latter need to be sent back to the user. The size of the results for task $j$ is denoted with
$r_j$, and the rate at which they are sent back to the user is $r^{'}_{i,j,t}$ on server $i$ at time $t$. Every task
has a beginning time, denoted by $b_j$ and a deadline, denoted by $d_j$. This is the maximum time for the task to be
completed in order for the user to derive its value. This time includes: the time required to send the data/code to the
server, run it on the server, and get back the results. Therefore for the task to be successfully completed, it must
completed fulfill the constraint in equation~\eqref{eq:deadline}. These operations must occur in order (loading,
computing then sending of results) as a server couldn't compute a task that was not fully loaded on the machine.

\begin{align}
    \frac{s_j}{\sum^{d_j}_{t=b_j} s^{'}_{i,j,t}} + \frac{w_j}{\sum^{d_j}_{t=b_j} w^{'}_{i,j,t}}  +
    \frac{r_j}{\sum^{d_j}_{t=b_j} r^{'}_{i,j,t}} \leq d_j && \forall{j \in J}  \label{eq:deadline}
\end{align}

As server have limited capacity, the total resource usages for all tasks running on a server must be capped.
The storage constraint (equation~\eqref{eq:server_storage_capacity}) is unique as the previous amount
loaded in kept till the end of a program on server. While the computation capacity
(equation~\eqref{eq:server_computation_capacity} is the sum of compute used by all of the tasks on a server $i$ at time $t$ and the
bandwidth capacity (equation~\eqref{eq:server_bandwidth_capacity}) is the sum of loading and sending usages by tasks.
\begin{align}
    \sum_{j \in J} \left(\sum^{d_j}_{t=b_j} s^{'}_{i,j,t} \right) \leq S_i, && \forall{i \in I} \label{eq:server_storage_capacity} \\
    \sum_{j \in J} w^{'}_{i,j,t} \leq W_i, && \forall{i \in I, t \in T} \label{eq:server_computation_capacity} \\
    \sum_{j \in J} s^{'}_{i,j,t} + r^{'}_{i,j,t} \leq R_i, && \forall{i \in I, t \in T} \label{eq:server_bandwidth_capacity} \\
\end{align}

% Todo add complete mathematical description of the problem

\section{Auctioning of Tasks}

\section{Markov Decision Process}

\section{Proposed Agents}

\section{Task Auctioning solution}\label{sec:task-auctioning}
While the mathematically description of the problem presented above doesn't contain any auctioning properties, in real
life, cloud providers wish to be paid to the use of their services. However due to the modifications that
this project has to make to the optimisation problems compared to a traditional cloud computing optimisation problem.
All traditional auction mechanisms that have been discussed in section~\ref{sec:related-work-in-cloud-computing} means
that a novel or modified auction mechanism must be used to deal with these changes. Due to the complexities of devising
new auction mechanism and the large corpus of research on auctions already, this project has chosen to use the Vickrey
auction~\citep{vickrey}.

This is as the modification required for an auction mechanism to be used is not to the auction itself but to the way
that server price tasks. In traditional cloud computing, it was possible to create combinations of resources that means
that users just buy the minimum amount of resources for their task with the price determined by the amount of
resources requested. But due to the flexible resource allocation mechanism this style of linear pricing strategy is not
effective as the demand on resources is not easy to calculate and the resource usage by other tasks is difficult to
predict in the future.

If an user wishes to run on task on the cloud, the task can be put forward with its
requirements of required storage, computation, results data and deadline.

%In order for fast and truthful, a reverse Vickrey auction~\citep{vickrey}
%will be implemented  where servers all submit their bid for the task with the winner being the server with the lowest
%price but actually only gains second lowest price. The Vickrey auction is incentive compatible meaning that the dominant
%strategy for bidding on a task is to bid your truthful value for a task. This should help server as they dont need
%to learn how to outbid another agent as it only needs to consider its own evaluation.
%As there is also only a single round of bidding compared to alternative auctions like English or Dutch
%auctions, this makes auctioning fast no matter the number of servers and it also allows for a reserve price to be used.

In order to calculate the price of the task for a server requires a understanding the resource requirements of the task,
the future supply and demand for tasks and the resource requirements of currently allocated tasks. Due to the complexity
in creating a heuristic that can accurately use this information and the amount of memory required for a table based
approach. Because of this, a long/short term memory (LSTM) will be implemented~\citep{LSTM}  for evaluating the price
of a task. The justified for the use of this network over other neural network models is explained in
Section~\ref{sec:justification-for-task-auctioning}. The network would take as input, the currently
allocated tasks requirements, the possible task requirements and the server resource capacity, outputting just a single
value representing the price of the task, normalised between 0 and 100.

\section{Resource allocation solution}\label{sec:resource-allocation-solution}
In previous work~\citep{FlexibleResourceAllocation}, that utilised a single shot problem case where jobs wouldnt arrive
over time, the resource speeds set were fixed and assumed that a task loading, computing and sending result
occurred concurrently. With the addition of time, results in these assumptions not to hold anymore as tasks contain
stages for the loading, computing and sending of results thus requiring allocated resource speeds to change over time.
Therefore at each time step, a server needs to reallocate all of its resource to its currently allocated tasks as
some tasks will have completely one of its stages.

In order to select how to allocate resource to tasks, this problem doesn't seem as complex as the pricing in
section~\ref{sec:task-auctioning} therefore simple heuristic and long/short term memory neural network will be
implemented and compared. This is justified in section~\ref{sec:justification-for-task-auctioning}. The LSTM will take as input, all of
the currently allocated tasks that are at a particular stages resource requirements and the task's resource requirement
returning a single value between 1 to 100. Once this is completed for each job, the percentage of the total values will
be assigned to each task.
\section{Markov Decision Process Environment}\label{sec:markov-decision-process-description}
Markov decision process~\citep{} is a mathematical framework that is used in reinforcement learning to model actions,
states and rewards.
\begin{figure}
    \includegraphics{}
    \caption{}
    \label{fig:mdp}
\end{figure}

But because of the way that the problem must be formulaed with the two sub-problems of auctioning and resource
allocation that means that a straight forward implementation of this framework is difficult. This is the system works
in batches with new tasks arriving over time that is then auctioned which could occur multiple times till all tasks
are auctioned. Then server redistributes their resources which means that the overall markov decision process has
two separate sub-environment within the overall larger environment. Because this problem of this, multiple