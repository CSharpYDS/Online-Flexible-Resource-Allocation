\chapter{Testing}\label{ch:testing-of-the-implementation}
To confirm that the environment and agents implemented in the previous chapter
(section~\ref{sec:implementing-auction-and-resource-allocation-agents}), functional testing has been done to assert that
all is working as expected. The tests implemented are explained in section~\ref{sec:functional-testing}. In order to
test and compare implemented agents and neural network architectures from Chapter~\ref{ch:implementation-of-the-solution},
a range of metrics have been implemented during evaluation of the agents. Agents are also saved at the end of training,
to allow for further evaluation of agents in Chapter~\ref{ch:evaluation-of-the-solution}.

\section{Functional testing}\label{sec:functional-testing}
To confirm that the implementation of the agents and environment correctly, PyTest a module within python has been used
to create tests. The tests are split into three families: agent, environment and training that are explained
in the respective tables~\ref{tab:agent_testing},~\ref{tab:env_testing} and~\ref{tab:training_testing}.

\begin{longtable}{|p{3cm}|p{11cm}|} \hline
    \textbf{Testing name} & \textbf{Explanation} \\ \hline
    Building agents & Constructs all of the agents with possible arguments to confirm agents can accept of all its
        attributes\\ \hline
    Saving agents & Confirms that agents can successfully save their neural networks and can successfully load
        the network again and is equal to the agent network. \\ \hline
    Agent actions & Confirms that all agents can generate valid actions for both bidding and weighting \\ \hline
    Gin config file & Gin is used to set the arguments used during training, to confirm that the file is valid. \\ \hline
    Building networks & Constructs all of the neural networks to confirm that the network return a valid output. \\ \hline
    Agent epsilon policy & While training, some of the agent actions are randomly selected to train the agents over
        a large area of the state. This tests that the random actions selected are valid. \\ \hline
    \caption{Table of testing functions for the agent}
    \label{tab:agent_testing}
\end{longtable}

\begin{longtable}{|p{3cm}|p{11cm}|} \hline
    \textbf{Testing name} & \textbf{Explanation} \\ \hline
    Saving and loading an environment & The environment allows for the saving the environment at its current
        state. This tests that the environment can save and reload the environment successfully. \\ \hline
    Loading environment settings & Tests that the load environment settings correctly generates a new random
        environment based on the settings. \\ \hline
    Random action environment steps & To tests that inputs to the auction and resource allocation steps are valid,
        random actions are generated for the environment, that is repeated for the whole environment.  \\ \hline
    Auction step & To confirm the Vickrey auction mechanism is completely implemented, a range of possible inputs
        are tested to confirm that right price and server the task is allocated to. \\ \hline
    Resource allocation step & To confirm that servers allocate their resources correct given some inputs. \\ \hline
    Allocation of computational resources & Checks that the server correctly allocates computational resources to
        allocated tasks. \\ \hline
    Allocation of storage and bandwidth resources & Checks that the server correctly allocates storage and
        bandwidth resources to allocated tasks. \\ \hline
    Allocation of all resources & Checks that resources are allocated by the server correctly for all of the
        resources. \\ \hline
    \caption{Table of testing functions for the environment}
    \label{tab:env_testing}
\end{longtable}

\begin{longtable}{|p{3cm}|p{11cm}|} \hline
    \textbf{Testing name} & \textbf{Explanation} \\ \hline
    Task pricing training & Tests that the task pricing reinforcement learning agents can correctly learning from
        different auction observations. \\ \hline
    Resource allocation training & Tests that resource allocation reinforcement learning agents can correctly
        learning from different resource allocation observations. \\ \hline
    Agent evaluation & Tests that the agent evaluation function for during training correctly captures the correct
        information due to the actions taken. \\ \hline
    Agent training & Tests that agents can be correctly trained over an environment with different actions and
        observations. \\ \hline
    Random actions training & Tests that agents with random actions that can quickly using the environment training
        methods to confirm that the function work as intended. \\ \hline
    \caption{Table of testing functions for agent training}
    \label{tab:training_testing}
\end{longtable}

\section{Agents training evaluation}\label{sec:evaluation-testing}
To compare the implemented agent training algorithms and neural networks architectures from
chapter~\ref{ch:implementation-of-the-solution}, tests are implemented to evaluation the effectiveness of training for
each of these agents. This is done using a range of metrics during the evaluation stage of training. For the
auction agent the metrics are a histogram winning prices, number of no bids, number of failed tasks, number of completed
tasks and a histogram of actions taken. For the resource allocation agents the metrics are a histogram of weighting,
number of failed tasks and number of completed tasks. These training tests fall into several distinct sections that are
explained in Table~\ref{tab:testing_areas}.

\begin{longtable}{|p{4cm}|p{10cm}|} \hline
    Test Name & Explanation \\ \hline
    Multi vs Single environment training settings & There are huge ranges of possible environment settings that
        agents could be trained for. This test investigates how good single environment trained agents react to
        a new environment and how agents compare on an environment when an agent is only trained on that
        environment or on multiple environments. \\ \hline
    Multi vs Single agent training settings & As the Vickrey auction is incentive compatible then it is
        possible to train both the auction agents and resource allocation against itself with a single agent. This
        test investigates the difference between the agent policies when self-trained or train with other
        agents. \\ \hline
    Reinforcement Learning algorithm testing & As multiple different reinforcement learning policy outlined in
        table~\ref{tab:reinforcement_learning_algorithms}, this test compares the results of the different agents
        against each other. \\ \hline
    Neural network architecture testing & There are a wide-range of compatible neural network architectures that
        agents can use, as outlined in table~\ref{tab:neural_network_layers}. To use these agents, the underlying
        policies are kept the same with a range of model networks are trained. \\ \hline
    Fixed heuristic policies testing & In order to compare to the reinforcement learning policies, a number of
        fixed heuristic policies are investigated both against other heuristics and reinforcement learning
        policies. \\ \hline
    \caption{Table of Testing Areas}
    \label{tab:testing_areas}
\end{longtable}
