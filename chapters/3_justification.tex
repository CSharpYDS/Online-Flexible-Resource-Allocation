\chapter{Justification of the solution}\label{ch:justification-of-the-solution}
The proposed solution in Chapter~\ref{ch:proposed-solution-to-problem} as two parts explained in
section~\ref{sec:task-auctioning} and~\ref{sec:resource-allocation-solution}. This chapter explains the reason for why each
section is being solved in its particular way.

As the approaches to pricing and resource allocation heuristics are using neural networks to find the optimal function,
table~\ref{tab:neural_network_description} has a description of how the networks architectures differ.

\begin{longtable}{|p{3.5cm}|p{11cm}|} \hline
    \textbf{Neural Network} & \textbf{Description} \\ \hline
    Artificial neural networks (ANN)~\cite{ANN} & Originally developed as a theoretically approximation for the brain,
        it was found that for networks with at least one hidden layer that a neural network could approximate any
        function~\citep{csaji2001approximation}. This made neural networks extremely helpful for cases where a function
        would normally to difficult to find the exact function, an ANN could be trained through supervised learning to
        be a close approximation to the true function. \\ \hline

    Recurrent neural network (RNN)~\cite{RNN} & A major weakness of ANN's is that it must use a fixed input and output
        making it unusable with text, sound or video where the previous data in important in understanding an input.
        RNN's extend ANN's to allow for connections to neurons again so that the network is not stateless compared to
        ANN. This means that individual letters of a words can be passed in with the network "remembering" the
        previous letter. \\ \hline

    Long/Short Term Memory (LSTM)~\cite{LSTM} & While RNN's can "remember" previous inputs to the network, it also
        struggles from the vanishing or exploding gradient problem where gradient tends to zero or infinity making it
        unuseable. LSTM aims to prevent this by using forget gates that determines how much information the next state
        will get, allowing for more complexity information to be learnt compared to RNN's\\ \hline

    Gated Recurrent unit (GRU)~\cite{GRU} & GRU are very similar to LSTM, except that they use different wiring and a
        single less gate, using an update gate instead of a forgot gate. These additional mean that the they run faster
        and are easier to code than LSTM however are not as expressive allowing for less complex functions to be
        encoded. \\ \hline

    Neural Turing Machine (NTM)~\cite{NTM} & Inspired by computers, neural turing machines build on LSTM by using an
        external memory module that instead of memory being inbuild in a neuron. This allows for external observers to
        understand what is going on much better than LSTM due to its black-box nature. \\ \hline

    Differentiable neural computer (DNC)~\cite{DNC} & An expansion to the NTM where the memory module is scalable in
        size allowing for additional memory to be added if needed. \\ \hline

    \caption{Neural network descriptions}
    \label{tab:neural_network_description}
\end{longtable}

\section{Justification for Task Auctioning}\label{sec:justification-for-task-auctioning}
The auction stage (discussed in Section~\ref{sec:task-auctioning}) has two considerations, the auction type and the pricing method.

In auction theory, there are numerous types of auctions that have different properties and uses in different areas.
The area in which this project is interested in is single indivisible items as while the item has multiple resource
requires, a server is required to buy the task as a single unit. Table~\ref{tab:auctions_descriptions} outlines a
description of possible auctions while table~\ref{tab:auction_properties} outline the most important properties that
an auction has.

\begin{longtable}{|p{3cm}|p{10cm}|} \hline
    \textbf{Auction type} & \textbf{Description} \\ \hline
    English auction & A traditional auction where all participant can bid on a single item with the price slowing ascending till
    only a single participant is left who pays the final bid price. Due to the number of rounds, this requires a large amount of
    communication and requires tasks to be auctioned in series. \\ \hline

    Dutch auction & The reverse of the English auction where the starting price is higher than anyone is willing to pay with the price
    slowly dropping till the first participant "jumps in". This can result in sub-optimal pricing if the starting price is not highest enough
    and the latency can have a large effect on the winner. \\ \hline

    Japanese auction & Similar to the English auction except that the auction occurs over a set period of time with the last highest
    bid being the winner. This means that it has the same disadvantages as the English auction except that there is no guarantee
    that the price will converge to the maximum. Plus additional factors like latency can have a large effect on the winner that
    will have a larger affect in the application of this project, edge cloud computing.
    But this time limit results in the auction taking a fixed amount of time unlike the English or Dutch auctions. \\ \hline

    Blind auction & Also known as a First-price sealed-bid auction, all participants submit a single secret bid for an item with the highest bid winning and
    pays their bid value. As a result there is no dominant strategy (not incentive compatible) as an agent would not wish to bid higher than their task evaluation
    but if all other agents bid significantly lower then it would have been beneficial for the agent to bid much lower than their true evaluation.
    Due there being a single round of biding, latency doesn't affect an agent and many more auctions could occur within the same time a English,
    Dutch or Japanese auction would take to run. \\ \hline

    Vickrey auction~\citep{vickrey} & Also known as a second-price sealed bid auction, all participants submit a single secret bid
    for an item with the highest bid winning but it only pays the price of the second highest bid. Because of this, it is a dominant
    strategy for an agent to bid its true value as even if the bid is much higher than all other participants its doesn't matter. \\ \hline

    \caption{Descriptions of auctions}
    \label{tab:auctions_descriptions}
\end{longtable}

\begin{table}[h]
    \centering
    \begin{tabular}{|l|c|c|c|} \hline
        Auction & Incentive compatible & Iterative & Fixed time length\\ \hline
        English & False & True & False \\ \hline
        Japanese & False & True & True \\ \hline
        Dutch & False & True & False \\ \hline
        Blind & False & False & True \\ \hline
        Vickrey & True & False & True \\ \hline
    \end{tabular}
    \caption{Properties of the auctions described in Table~\ref{tab:auctions_descriptions}}
    \label{tab:auction_properties}
\end{table}

Due to the properties of the Vickrey auction (table~\ref{tab:auction_properties}), I believe that it is the best auction to be used.
The greatest advantage of the auction is that it is strategyproof meaning the dominant strategy is to truthful bid its price.
This means that agents don't have to learn a strategy as with the blind auction where the agent must learn to bid only just
lower than other agents. Another advantage of the auction is that it is not iterative, making the auction fast with only a single
round and can give a fixed time limit from the task being published to all server bids to be submitted.

However, the standard Vickrey auction will not be used as the task is buying the resources from a server
not a server buying the task. But due to resource allocation, the server must bid on the task so the Vickrey auction implemented
will work in reverse so the lowest bid will win and the task must pay the second-lowest bid. In the final report, a proof will be provided
to show that a reverse Vickrey auction is still incentive compatible.

The second part of the auction solution is the pricing heuristic. I believe that the pricing heuristic would be too complex to encoded into
an algorithm if by hand due its need to understand: future resource allocation of currently allocated jobs and the resource requirements
of the task. Therefore due to neural network being able to approximate any function~\citep{csaji2001approximation} and reinforcement learning
methods to training without truth data (Section~\ref{sec:related-work-in-machine-learning}). I have outlined in Table~\ref{tab:neural_network_description} the properties of popular neural
network architectures that would allow for a variable amount of inputs (except for ANN). This is due to having to input to the network
the currently allocated tasks to a server that till compute time is of unknown length. Of the available architecture, I predict the
Long/Short term memory model is the simplest model that will require the least training but still with the complexity to encode the
heuristic. With the Neural Turing Machine and Differentiable Neural Network, these networks are extremely complex and require a large amount
of data to train the networks. Also the ability of these networks to be able to store data in external storage is not important as the data
doesn't need to be store for future inputs. The opposite problem exists for the Recurrent neural network or the Gated Recurrent unit that
they are possibly not complex enough for the pricing heuristic.

\section{Justification for Resource allocation}\label{sec:justification-for-resource-allocation}
The justification for the resource allocation neural network choice is very similar justification to the previous section
(section~\ref{sec:justification-for-task-auctioning}). Long/short term memory architecture should be complex enough for the resource allocation
but it is possible that the abilily to use external storage of Neural Turing machine and Differentiable Neural network to store the
allocation of resource to previous tasks. But I don't believe that this additional complexity will allow for the heuristic to do
later better but it could be investigated in future work.

The reason that the output of the neural network is normalised is done as it would require the network to learn less compared
to if the network has output the amount of the available resources for a task. Whereas in a normalised value, the network can
output how "important" allocation of resources are for a task not the exact amount of resources allocated.